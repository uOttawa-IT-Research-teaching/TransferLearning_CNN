{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd548b11-91e8-4188-b59a-92fd8e7de552",
   "metadata": {},
   "source": [
    "# Introduction to Convolutional Neural Networks (CNN)\n",
    "**Notebook 1 of 2**\n",
    "\n",
    "In our previous tutorials, we explored the fundamentals of deep neural networks (DNN).  We delved into the inner workings of how DNNs learn with the data.  This tutorial gives a cursory overview of how convolutional neural networks (CNN) work and why they are used in image and video inferencing. A more programmatic approach to CNNs is covered in the CNN for Image Inferencing tutorial [CNN in image Inferencing](https://github.com/uOttawa-IT-Research-teaching/CNN-ImageInferencing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28319f2",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "Average time to complete: 15min\n",
    "\n",
    "By the end of this tutorial you should be able to:\n",
    "* Understand the underlying concept of CNN models using the notions taught in the DNN / CNN intro workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95666577",
   "metadata": {},
   "source": [
    "## What you will need for this tutorial\n",
    "\n",
    "* See the [introduction document](https://uottawa-it-research-teaching.github.io/machinelearning/) for general requirements and how Jupyter notebooks work.\n",
    "* We'll need Pandas for convenient data handling. It's a very powerful Python package that can read CSV and Excel files. It also has very good data manipulation capabilities which come in use for data cleaning.\n",
    "* Tensorflow\n",
    "* We will use scikit learn as our machine learning package.\n",
    "* numpy \n",
    "* seaborn \n",
    "* matplotlib\n",
    "* requests\n",
    "* ipywidgets\n",
    "* The data files that should have come with this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c21938",
   "metadata": {},
   "source": [
    "## RDM best practices\n",
    "\n",
    "Good data handling for machine learning begins with good Research Data Managment (RDM). The quality of your source data will impact the outcome of your results, just like the reproducibility of your results will depend on the quality of your data sources, in addition to how you organize the data so that other people (and machines!) can understand and reuse it. \n",
    "\n",
    "We also need to respect a few research data management best practices along the way, these best practices are recommended by the [Digital Research Alliance of Canada](https://zenodo.org/records/4000989).\n",
    "\n",
    "SAVE YOUR RAW DATA IN ORIGINAL FORMAT\n",
    "* Don't overwrite your original data with a cleaned version.\n",
    "* Protect your original data by locking them or making them read-only.\n",
    "* Refer to this original data if things go wrong (as they often do).\n",
    "\n",
    "BACKUP YOUR DATA\n",
    "* Use the 3-2-1 rule: Save three copies of your data, on two different storage mediums, and one copy off site. The off site storage can be OneDrive or Google drive or whatever your institution provides.\n",
    "* We are using Open Data, so it does not contain any personally identifiable data or data that needs to be restricted or protected in any way. However, if your data contains confidential information, it is important to take steps to restrict access and encrypt your data.\n",
    "\n",
    "There are a few more RDM best practices that will help you in your project management, and we will highlight them at the beginning of each tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c4f65",
   "metadata": {},
   "source": [
    "There are just a few libraries to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d421852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58097e34-8584-4683-9cbb-f1d5f3d165d8",
   "metadata": {},
   "source": [
    "### What if we want to train an image classifier i.e. use an image as an input ?\n",
    "Let's start with some image basics:\n",
    "\n",
    "- An image is a **collection of pixels**.  For example, a 32x32 image has 1024 pixels.\n",
    "- Each pixel is an **intensity represented by a number** in a range [0, 255]. 0 is black and 1 is white.​\n",
    "- Colour images have 3 dimensions: **[width, height, depth]** where depth is usually 3.  Depth encodes the intensity of RGB values [Red, Green, Blue].<br>\n",
    "![](./pynb_pics/imageof8.jpg)\n",
    "<p style=\"text-align: center;\">An image is just a matrix of integers</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8fcc37",
   "metadata": {},
   "source": [
    "There are 2 major limitations to feeding this matrix into a DNN as seen earlier\n",
    "- Does not scale well to bigger images:​\n",
    "\n",
    "  - Most real-life images as far bigger than 1024 pixels.  For example, a colour image of 320x320x3 has a dimension of 307200.​\n",
    "\n",
    "- Does not consider the property of an image:​\n",
    "\n",
    "  - Locality: Nearby pixels are usually strongly correlated (See outline of '8' picture). Scaling breaks the pattern.​\n",
    "\n",
    "  - Translation invariance: Meaningful features can occur anywhere in image.​\n",
    "![](./pynb_pics/goose.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557779f1",
   "metadata": {},
   "source": [
    "Comment: here in the browser the image is not visible. Not sure if becuase it needs to be open in ganymede.uottawa.ca. If there is a glitch needs to be addressed.\n",
    "\n",
    "How **convolution** deals with these limitations:\n",
    "\n",
    " - **Weight Sharing**: All local parts of an image are processed with the same weights so that identical patterns can be detected at many location e.g. horizontal edges, curves, etc.\n",
    "\n",
    " - **Hierarchy of features**: Lower-level patterns learned at the start are composed to form higher-level ones across layers e.g. edges to contours to head outlines, etc.\n",
    "\n",
    "How does convolution work?\n",
    "\n",
    " - Define a filter: a 2D weight matrix of a certain size e.g. 3x3 filter\n",
    "\n",
    " - Convolve the whole image with the filter: multiply each pixel under the filter with the weight\n",
    "\n",
    " - Convolution output forms a new image: a feature map\n",
    "\n",
    " - Using multiple filters (each with a different weight matrix), different features can be captured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a84cf9",
   "metadata": {},
   "source": [
    "### Convolution example: mean filter\n",
    "\n",
    "Take an image with pixel values as follows​\n",
    "\n",
    "Comment: Describe the features of the image above as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ebc897f-f731-4e9b-bd94-e6863b0bc57b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fig,ax\u001b[38;5;241m=\u001b[39m\u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,subplot_kw\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maspect\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequal\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# A small 3x3 sample array\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Normalise the data to between 0 and 1\u001b[39;00m\n\u001b[0;32m      6\u001b[0m imarray\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m],\n\u001b[0;32m      7\u001b[0m  [\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m],\n\u001b[0;32m      8\u001b[0m  [\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m  [\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m],\n\u001b[0;32m     12\u001b[0m  [\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "fig,ax=plt.subplots(1,subplot_kw={'aspect':'equal'})\n",
    "\n",
    "# A small 3x3 sample array\n",
    "# Normalise the data to between 0 and 1\n",
    "\n",
    "imarray=np.array([[0., 0., 0., 0., 0., 0., 0.],\n",
    " [0., 0., 0., 0., 0., 0., 0.],\n",
    " [0., 0., 1., 1., 1., 0., 0.],\n",
    " [0., 0., 1., 1., 1., 0., 0.],\n",
    " [0., 0., 1., 1., 1., 0., 0.],\n",
    " [0., 0., 0., 0., 0., 0., 0.],\n",
    " [0., 0., 0., 0., 0., 0., 0.]])\n",
    "\n",
    "# plot the array\n",
    "ax.imshow(imarray,cmap='gray', interpolation='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421f1d4",
   "metadata": {},
   "source": [
    "Recall that a mean filter is a 2D matrix – 1 iteration​\n",
    "\n",
    "Comment: what does the sentence above mean? explain it plz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dfd7cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.11, 0.11, 0.11], [0.11, 0.11, 0.11], [0.11, 0.11, 0.11]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[.11, .11, .11],\n",
    "[.11, .11, .11],\n",
    "[.11, .11, .11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee82899",
   "metadata": {},
   "source": [
    "In a convolution, this \"mean filter\" slides across the image, takes values of 9 connected pixels, multiplies with the weights and returns sum i.e. the result is a weighted average (mean) of the 9 values hence \"mean filter\"\n",
    "\n",
    "Comment: the value is always 9 or in this case? please explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122e895",
   "metadata": {},
   "source": [
    "### Convolution layer in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ce463d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559956944ee143c3ad9f6ae66858b2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00\\x18ftypmp42\\x00\\x00\\x00\\x00mp41isom\\x00\\x00\\x00(uuid\\\\\\xa7\\x08\\xfb2\\x8eB\\x05...', h…"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video.from_file(\"./pynb_pics/meanfilter.mp4\", width=320, height=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e8740",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "Below is an example of the the averaging effect in an area of the image.  Notice how it blurs out any edges in the image.  This represents the initial stages of feature detections in the training image that the model will use to identify objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f64f0107-6e72-45a1-b6d5-aaf1c64208e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots(1,subplot_kw={'aspect':'equal'})\n",
    "\n",
    "# After applying filter - one iteration\n",
    "imarray=np.array([[0.11, 0.22, 0.33, 0.22, 0.11],\n",
    " [0.22, 0.44, 0.67, 0.44, 0.22],\n",
    " [0.33, 0.67, 1.,   0.67, 0.33],\n",
    " [0.22, 0.44, 0.67, 0.44, 0.22],\n",
    " [0.11, 0.22, 0.33, 0.22, 0.11]])\n",
    "\n",
    "# plot the array\n",
    "ax.imshow(imarray,cmap='gray', interpolation='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26c344c",
   "metadata": {},
   "source": [
    "### Learning features\n",
    "\n",
    "Comment: try to explian this heading a form of paragraphand then include the point below.\n",
    "\n",
    "- Usually there are many filters for each layer\n",
    "- Each filter captures a different pattern of the same image\n",
    "- Multiple layers allow features at different scales to be captured.  This is the hierarchy of features referred to earlier.\n",
    "- Early filters capture edges and textures\n",
    "- Later filters form parts and objects\n",
    "![](./pynb_pics/layers.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506a375d",
   "metadata": {},
   "source": [
    "### Putting DNNs and CNNs together\n",
    "\n",
    "Comment: what is the purpose of putting DNN and CNN together? explain here.\n",
    "\n",
    "#### DNN uses many fully-connected layers\n",
    "Comment: explain the heading above.\n",
    "\n",
    "#### CNN contains mostly convolutional layers\n",
    "Comment: explain the heading above\n",
    "- Convolutional layer: Image undergoes a convolution with filters\n",
    "- RELU layer: Activation function to introduce non-linearity in order to reduce error as much as possible (same function as with DNN)\n",
    "- Pooling layer: Image undergoes a convolution with a mean (or max) filter. Down-sampling and feature preservation.  Saves time and computations.\n",
    "- Fully-connected layer: Last layer to output a class probability prediction.  That's what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090e916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64054433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
